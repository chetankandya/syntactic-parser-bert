{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bert_parser.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "2Wx9nSE47_aP"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Install and import necessary packages."
      ],
      "metadata": {
        "id": "K1h_JKLnZkk5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "BdY0zSUHzzlJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import math\n",
        "from transformers import BertTokenizer, BertModel\n",
        "from collections import Counter\n",
        "from operator import itemgetter\n",
        "from torch.utils.data import Dataset as torch_dataset\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn as nn\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "M5mTP051q0jJ"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " Set device - GPU/CPU."
      ],
      "metadata": {
        "id": "NeJqnQmMaE7W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
      ],
      "metadata": {
        "id": "pqmketkMZ7ty"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check GPU type"
      ],
      "metadata": {
        "id": "2Wx9nSE47_aP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install gputil\n",
        "!pip install psutil\n",
        "!pip install humanize\n",
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU"
      ],
      "metadata": {
        "id": "WlS2JNO3MEyz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check gpu ram \n",
        "GPUs = GPU.getGPUs()\n",
        "# XXX: only one GPU on Colab and isnâ€™t guaranteed\n",
        "gpu = GPUs[0]\n",
        "def printm():\n",
        "  print(gpu.name)\n",
        "  process = psutil.Process(os.getpid())\n",
        "  print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
        "  print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "printm()"
      ],
      "metadata": {
        "id": "qhfReejI77vg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prepare data"
      ],
      "metadata": {
        "id": "TyBIA4YBf0eR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Read the data from the files and extract relevant information."
      ],
      "metadata": {
        "id": "JXGmuUFo6eSG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9RjKQCv_NJeo"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# change this to the path in google drive where the files are located\n",
        "%cd /content/drive/MyDrive/TDDE09 Project/Code"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Dataset():\n",
        "\n",
        "    def __init__(self, filename):\n",
        "        self.filename = filename\n",
        "\n",
        "    def __iter__(self):\n",
        "        with open(self.filename, 'rt', encoding='utf-8') as lines:\n",
        "            tmp = []\n",
        "            for line in lines:\n",
        "                if not line.startswith('#'):  # Skip lines with comments\n",
        "                    line = line.rstrip()\n",
        "                    if line:\n",
        "                        columns = line.split('\\t')\n",
        "                        if columns[0].isdigit():  # Skip range tokens\n",
        "                            tmp.append((columns[1], columns[3], int(columns[6])))\n",
        "                    else:\n",
        "                        yield tmp\n",
        "                        tmp = []"
      ],
      "metadata": {
        "id": "KxHoMdHSnFi1"
      },
      "execution_count": 236,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# read the data (not projectivized)\n",
        "train_data = Dataset('en_ewt-ud-train.conllu')\n",
        "dev_data = Dataset('en_ewt-ud-dev.conllu')\n",
        "test_data = Dataset('en_ewt-ud-test.conllu')"
      ],
      "metadata": {
        "id": "HBV3gwAJQYvf"
      },
      "execution_count": 237,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Parser dataset\n",
        "Dataset class to be used by the dataloader. Sentences are extracted and stored as individual strings and gold heads are also stored."
      ],
      "metadata": {
        "id": "a9yiDn0w7eTZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ParserDataset(torch_dataset):\n",
        "    def __init__(self, dataset, max_size=None):\n",
        "        self.xs, self.ys = [], []\n",
        "        self.sent_lens = []\n",
        "        \n",
        "        sorted_dataset = sorted(dataset, key=lambda sentence: len(sentence))\n",
        "\n",
        "        for sentence in sorted_dataset:\n",
        "            words, tags, heads = zip(*sentence)\n",
        "            self.sent_lens.append(len(sentence))\n",
        "\n",
        "            if max_size != None and len(self.xs) >= max_size:\n",
        "                break\n",
        "            \n",
        "            self.xs.append(' '.join(words))\n",
        "            self.ys.append(list(heads))\n",
        "            \n",
        "    def __getitem__(self, idx):\n",
        "        return self.xs[idx], self.ys[idx]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.xs)"
      ],
      "metadata": {
        "id": "AxMuyMTxqDcd"
      },
      "execution_count": 238,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test the ParserDataset class and plot sentence lengths\n",
        "train_dataset = ParserDataset(train_data)\n",
        "dev_dataset = ParserDataset(dev_data)\n",
        "plt.plot(train_dataset.sent_lens)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "WcBs1Son-t1x",
        "outputId": "2f06df13-1ce5-4192-99e6-c90ea1272c75"
      },
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# BERT parser"
      ],
      "metadata": {
        "id": "1167mNAsqvzg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Get subwords indices\n",
        "Output from the bert tokenizer can split words that are not in the vocabulary. The following function gets indices for each token that indicate which actual word the token belongs to."
      ],
      "metadata": {
        "id": "mfap_OId7RPL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_word_level_indices(tok_sentence):\n",
        "    indices = []\n",
        "    subword_start, pad = 0, 0\n",
        "    for i in range(len(tok_sentence)):\n",
        "        if tok_sentence[i].startswith(\"##\") and not tok_sentence[i-1].startswith(\"##\"):\n",
        "            start = i-pad-1\n",
        "            pad += 1\n",
        "            indices.append(start)\n",
        "        elif(tok_sentence[i].startswith(\"##\") and tok_sentence[i-1].startswith(\"##\")):\n",
        "            pad += 1\n",
        "            indices.append(start)\n",
        "        else:\n",
        "            indices.append(i-pad)\n",
        "    return indices"
      ],
      "metadata": {
        "id": "swUUkVk49KV4"
      },
      "execution_count": 239,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# example usage\n",
        "tokens = ['the', 'quick', 'br', '##own', 'fox', 'jump', '##s']\n",
        "print(get_word_level_indices(tokens))"
      ],
      "metadata": {
        "id": "QIWi8IkymC79",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba818005-1707-45b7-94b1-e6b0ac26c5f7"
      },
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 1, 2, 2, 3, 4, 4]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Batchifyer\n",
        "The BertBatcher class tokenizes, adds padding and batches the dataset. Here, the labels are also converted into a matrix format that is used in the binary cross entropy loss function."
      ],
      "metadata": {
        "id": "vqzDHutV7D7q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BertBatcher():\n",
        "    def __init__(self, device):\n",
        "        self.device = device\n",
        "        self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "    def __call__(self, batch):\n",
        "        \n",
        "        labels = [label for sentence, label in batch]\n",
        "        sentences = [sentence for sentence, label in batch]\n",
        "        max_sentence_len = max([len([\"[CLS]\"] + self.tokenizer.tokenize(sentence) + [\"[SEP]\"]) for sentence in sentences])\n",
        "        \n",
        "        # create label matrix to be used in binary cross entropy\n",
        "        new_labels = []\n",
        "        for label in labels:\n",
        "            label_mat = torch.zeros(max_sentence_len-1, max_sentence_len)\n",
        "            for i, head in enumerate(label):\n",
        "                label_mat[i, head] = 1.0\n",
        "            new_labels.append(label_mat)\n",
        "\n",
        "        # save word-level indices\n",
        "        word_level_indices = []\n",
        "        for sentence in sentences:\n",
        "            sent_tokens = [\"[CLS]\"] + self.tokenizer.tokenize(sentence) + [\"[SEP]\"]\n",
        "            sent_tokens_padded = sent_tokens + [\"[PAD]\"] * (max_sentence_len - len(sent_tokens))\n",
        "            word_level_indices.append(get_word_level_indices(sent_tokens_padded))\n",
        "\n",
        "        # tokenize all sentences in the batch and add padding\n",
        "        processed_sentence = self.tokenizer(sentences, padding=\"max_length\", return_tensors=\"pt\", max_length=max_sentence_len)\n",
        "        input_ids, attention_mask = itemgetter(\"input_ids\", \"attention_mask\")(processed_sentence)\n",
        "\n",
        "        return (input_ids.to(self.device), \n",
        "                attention_mask.to(self.device), \n",
        "                torch.stack(new_labels).to(self.device), \n",
        "                torch.tensor(word_level_indices).to((self.device)))"
      ],
      "metadata": {
        "id": "AF4JqGBbivPF"
      },
      "execution_count": 240,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test batcher and dataloader\n",
        "train_dataset = ParserDataset(train_data, max_size=10)\n",
        "dev_dataset = ParserDataset(dev_data, max_size=10)\n",
        "bert_batcher = BertBatcher(device)\n",
        "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=32, collate_fn=bert_batcher)\n",
        "test_dataloader = torch.utils.data.DataLoader(dev_dataset, batch_size=32, collate_fn=bert_batcher)\n",
        "\n",
        "for example in train_dataloader:\n",
        "    input_ids, attention_mask, labels, word_level_indices = example\n",
        "    break"
      ],
      "metadata": {
        "id": "hvGx2q9HiaUS"
      },
      "execution_count": 241,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# shapes for the output from the batcher\n",
        "print(input_ids.shape)\n",
        "print(attention_mask.shape)\n",
        "print(labels.shape)\n",
        "print(word_level_indices.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HuMLKGQSi6Lz",
        "outputId": "f4abc40c-dc1b-4633-a312-421ea982ffeb"
      },
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([10, 37])\n",
            "torch.Size([10, 37])\n",
            "torch.Size([10, 36, 37])\n",
            "torch.Size([10, 37])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Customized BERT model\n",
        "The components in the final customized BERT model, including the biaffine attention layer and a function for doing word-level average pooling."
      ],
      "metadata": {
        "id": "uFJ64JE967Ky"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Biaffine(nn.Module):\n",
        "    def __init__(self, n_in, n_out=1, bias_x=True, bias_y=True):\n",
        "        super(Biaffine, self).__init__()\n",
        "\n",
        "        self.n_in = n_in\n",
        "        self.n_out = n_out\n",
        "        self.bias_x = bias_x\n",
        "        self.bias_y = bias_y\n",
        "        self.weight = nn.Parameter(torch.Tensor(n_out, n_in + bias_x, n_in + bias_y))\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        bound = 1 / math.sqrt(self.weight.size(1))\n",
        "        nn.init.uniform_(self.weight, -bound, bound)\n",
        "\n",
        "    def forward(self, x, y):\n",
        "        if self.bias_x:\n",
        "            x = torch.cat([x, x.new_ones(x.shape[:-1]).unsqueeze(-1)], -1)\n",
        "        if self.bias_y:\n",
        "            y = torch.cat([y, y.new_ones(y.shape[:-1]).unsqueeze(-1)], -1)\n",
        "        # [batch_size, 1, seq_len, d]\n",
        "        x = x.unsqueeze(1)\n",
        "        # [batch_size, 1, seq_len, d]\n",
        "        y = y.unsqueeze(1)\n",
        "        # [batch_size, n_out, seq_len, seq_len]\n",
        "        s = x @ self.weight @ y.transpose(-1, -2)\n",
        "        # remove dim 1 if n_out == 1\n",
        "        s = s.squeeze(1)\n",
        "\n",
        "        return s"
      ],
      "metadata": {
        "id": "BKtwEwrfGYbN"
      },
      "execution_count": 242,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomBERTModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CustomBERTModel, self).__init__()\n",
        "        self.model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
        "        self.biaffine = Biaffine(768) # 786 is the hidden dim in the BERT model\n",
        "        self.dropout = torch.nn.Dropout(p=0.1)\n",
        "\n",
        "    def word_level_pooling(self, last_hidden_state, word_level_indices):\n",
        "        pooled_hidden = torch.zeros_like(last_hidden_state)\n",
        "        for b in range(last_hidden_state.shape[0]):\n",
        "            c = Counter(word_level_indices[b])\n",
        "            padding = 0\n",
        "            for idx in set(word_level_indices[b]):\n",
        "                if c[idx] > 1:\n",
        "                    padding += c[idx]-1\n",
        "                    pooled_hidden[b][idx] = torch.mean(last_hidden_state[b][idx:idx+padding+1], dim=0)\n",
        "                else:\n",
        "                    pooled_hidden[b][idx] = last_hidden_state[b][idx+padding] \n",
        "        return pooled_hidden\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, word_level_indices):\n",
        "        model_out  = self.model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        last_hidden_state = model_out[0]\n",
        "\n",
        "        # apply word-level pooling and dropout\n",
        "        pooled_last_hidden = self.word_level_pooling(last_hidden_state, word_level_indices)\n",
        "        pooled_last_hidden = self.dropout(pooled_last_hidden)\n",
        "\n",
        "        X = pooled_last_hidden[:, 1:pooled_last_hidden.shape[1], :]\n",
        "        X_prime = pooled_last_hidden[:, :pooled_last_hidden.shape[1], :]\n",
        "        Y_arc = self.biaffine(X, X_prime)\n",
        "\n",
        "        return Y_arc"
      ],
      "metadata": {
        "id": "L84UkcotGdYT"
      },
      "execution_count": 243,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test forward method\n",
        "m = CustomBERTModel().to(device)\n",
        "l = m.forward(input_ids[0:2], attention_mask[0:2], word_level_indices[0:2])"
      ],
      "metadata": {
        "id": "MOnVbh5dGYIg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Parser class\n",
        "Class to instantiate, train and evaluate the parser."
      ],
      "metadata": {
        "id": "6wQayrj06qMS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BertParser():\n",
        "\n",
        "    def __init__(self):\n",
        "        self.device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "        self.train_dataset = ParserDataset(train_data)\n",
        "        self.dev_dataset = ParserDataset(dev_data)\n",
        "        self.bert_batcher = BertBatcher(self.device)\n",
        "        self.custom_bert = CustomBERTModel().to(self.device)\n",
        "\n",
        "    def train(self, n_epochs=30, batch_size=8, lr=1e-5):\n",
        "        \n",
        "        train_loader = torch.utils.data.DataLoader(self.train_dataset, batch_size, collate_fn=self.bert_batcher)\n",
        "        self.custom_bert.train()\n",
        "        optimizer = torch.optim.AdamW(self.custom_bert.parameters(), lr=lr)\n",
        "        info = {'epoch': 0, 'training_loss': 0, 'validation_UAS': 0} # training loss is per batch\n",
        "\n",
        "        for epoch in range(n_epochs):\n",
        "            info['epoch'] = epoch + 1\n",
        "            with tqdm(total = len(train_loader)) as pbar:\n",
        "\n",
        "                self.custom_bert.train()\n",
        "                for input_ids, attention_mask, labels, word_level_indices in train_loader:\n",
        "\n",
        "                    optimizer.zero_grad()\n",
        "                    output = self.custom_bert.forward(input_ids, attention_mask, word_level_indices)                  \n",
        "\n",
        "                    # get indices for where the padding starts\n",
        "                    pad_indices = []\n",
        "                    for i, j in enumerate(labels):\n",
        "                        pad_indices.append(int(torch.sum(labels[i]).item()))\n",
        "\n",
        "                    # create weights so that padding can be ignored in loss calculation\n",
        "                    weights = torch.zeros_like(output).to(device)\n",
        "                    for i, row in enumerate(weights):\n",
        "                        row[:pad_indices[i], :pad_indices[i]+1] = 1\n",
        "\n",
        "                    # calculate loss and backpropagate \n",
        "                    bce_loss = nn.BCEWithLogitsLoss(weight=weights)\n",
        "                    loss = bce_loss(output, labels)\n",
        "                    loss.backward()\n",
        "                    optimizer.step()\n",
        "\n",
        "                    info['training_loss'] = f'{loss.item():.6f}'\n",
        "                    pbar.set_postfix(info)\n",
        "                    pbar.update()\n",
        "                \n",
        "                # run evaluation on current epoch\n",
        "                epoch_uas = self.evaluate()\n",
        "\n",
        "                info['validation_UAS'] = f'{epoch_uas:.6f}'\n",
        "                pbar.set_postfix(info)\n",
        "                pbar.update()\n",
        "\n",
        "\n",
        "    def evaluate(self, batch_size=8):\n",
        "\n",
        "        dev_loader = torch.utils.data.DataLoader(self.dev_dataset, batch_size, collate_fn=self.bert_batcher)\n",
        "        self.custom_bert.eval()\n",
        "\n",
        "        accuracy, num_heads = 0, 0\n",
        "        for input_ids, attention_mask, labels, word_level_indices in dev_loader:\n",
        "\n",
        "            pad_indices = []\n",
        "            for i, j in enumerate(labels):\n",
        "                pad_indices.append(int(torch.sum(labels[i]).item()))\n",
        "\n",
        "            with torch.no_grad():\n",
        "                output = self.custom_bert.forward(input_ids, attention_mask, word_level_indices)\n",
        "\n",
        "            for i, sentence in enumerate(output):\n",
        "                predictions = torch.argmax(output[i, :pad_indices[i], :pad_indices[i]+1], dim=1)\n",
        "                ys = torch.argmax(labels[i, :pad_indices[i], :pad_indices[i]], dim=1)\n",
        "                accuracy += torch.sum(predictions == ys).item()\n",
        "                num_heads += predictions.shape[0]\n",
        "\n",
        "        return accuracy/num_heads\n",
        "\n",
        "    def predict(self):\n",
        "        pass"
      ],
      "metadata": {
        "id": "5YqLLh84W9sF"
      },
      "execution_count": 245,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "parser = BertParser()"
      ],
      "metadata": {
        "id": "iq-SJnU0YnBd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train parser\n",
        "parser.train(n_epochs=30, batch_size=8, lr=1e-5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-0AcEA5TYsAE",
        "outputId": "cec527a0-68ee-405d-a794-bca57a99213f"
      },
      "execution_count": 247,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "1569it [02:46,  9.40it/s, epoch=1, training_loss=0.021128, validation_UAS=0.290946]\n",
            "1569it [02:46,  9.41it/s, epoch=2, training_loss=0.018716, validation_UAS=0.518152]\n",
            "1569it [02:46,  9.42it/s, epoch=3, training_loss=0.017161, validation_UAS=0.604358]\n",
            "1569it [02:47,  9.39it/s, epoch=4, training_loss=0.016326, validation_UAS=0.652233]\n",
            "1569it [02:46,  9.40it/s, epoch=5, training_loss=0.015866, validation_UAS=0.683327]\n",
            "1569it [02:46,  9.42it/s, epoch=6, training_loss=0.015625, validation_UAS=0.710326]\n",
            "1569it [02:47,  9.39it/s, epoch=7, training_loss=0.014763, validation_UAS=0.728260]\n",
            "1569it [02:46,  9.41it/s, epoch=8, training_loss=0.014254, validation_UAS=0.743847]\n",
            "1569it [02:46,  9.41it/s, epoch=9, training_loss=0.013931, validation_UAS=0.754821]\n",
            "1569it [02:46,  9.40it/s, epoch=10, training_loss=0.013660, validation_UAS=0.763569]\n",
            "1569it [02:46,  9.41it/s, epoch=11, training_loss=0.013503, validation_UAS=0.767585]\n",
            "1569it [02:46,  9.42it/s, epoch=12, training_loss=0.013518, validation_UAS=0.776492]\n",
            "1569it [02:46,  9.40it/s, epoch=13, training_loss=0.012795, validation_UAS=0.780389]\n",
            "1569it [02:46,  9.40it/s, epoch=14, training_loss=0.012741, validation_UAS=0.785280]\n",
            "1569it [02:46,  9.40it/s, epoch=15, training_loss=0.012635, validation_UAS=0.785717]\n",
            "1569it [02:46,  9.41it/s, epoch=16, training_loss=0.012466, validation_UAS=0.789733]\n",
            "1569it [02:46,  9.41it/s, epoch=17, training_loss=0.012494, validation_UAS=0.791324]\n",
            "1569it [02:47,  9.39it/s, epoch=18, training_loss=0.012335, validation_UAS=0.787427]\n",
            "1569it [02:47,  9.39it/s, epoch=19, training_loss=0.012963, validation_UAS=0.781582]\n",
            "1569it [02:46,  9.40it/s, epoch=20, training_loss=0.012609, validation_UAS=0.785916]\n",
            "1569it [02:48,  9.33it/s, epoch=21, training_loss=0.011971, validation_UAS=0.782377]\n",
            "1569it [02:46,  9.41it/s, epoch=22, training_loss=0.012180, validation_UAS=0.782457]\n",
            "1569it [02:46,  9.42it/s, epoch=23, training_loss=0.012064, validation_UAS=0.783888]\n",
            "1569it [02:46,  9.40it/s, epoch=24, training_loss=0.012106, validation_UAS=0.783968]\n",
            "1569it [02:46,  9.40it/s, epoch=25, training_loss=0.011647, validation_UAS=0.804088]\n",
            "1569it [02:46,  9.44it/s, epoch=26, training_loss=0.011743, validation_UAS=0.812557]\n",
            "1569it [02:46,  9.42it/s, epoch=27, training_loss=0.011079, validation_UAS=0.819993]\n",
            "1569it [02:46,  9.41it/s, epoch=28, training_loss=0.011143, validation_UAS=0.821742]\n",
            "1569it [02:47,  9.38it/s, epoch=29, training_loss=0.011398, validation_UAS=0.826037]\n",
            "1569it [02:47,  9.39it/s, epoch=30, training_loss=0.010848, validation_UAS=0.824844]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# do final evaluation on development data\n",
        "parser.evaluate()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mNZIndPPYtvb",
        "outputId": "1896d2dd-df30-4108-ab24-89889787bf29"
      },
      "execution_count": 248,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8248439301761501"
            ]
          },
          "metadata": {},
          "execution_count": 248
        }
      ]
    }
  ]
}