{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "baseline.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Prepare data"
      ],
      "metadata": {
        "id": "TyBIA4YBf0eR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9RjKQCv_NJeo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a68eb2d1-d228-4d7a-8b5a-6fe1cf79ef50"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/.shortcut-targets-by-id/1NeFHUkpRXe8AvGwOOij0YjGFr79_V8SQ/TDDE09 Project/Code\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# change this to the path in google drive where the files are located\n",
        "%cd /content/drive/MyDrive/TDDE09 Project/Code"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# projectivize trees\n",
        "!python projectivize.py < en_ewt-ud-train.conllu > en_ewt-ud-train-projectivized.conllu\n",
        "!python projectivize.py < en_ewt-ud-dev.conllu > en_ewt-ud-dev-projectivized.conllu\n",
        "!python projectivize.py < en_ewt-ud-test.conllu > en_ewt-ud-test-projectivized.conllu"
      ],
      "metadata": {
        "id": "GkGy-dIXNZ1W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Dataset():\n",
        "\n",
        "    ROOT = ('<root>', '<root>', 0)\n",
        "\n",
        "    def __init__(self, filename):\n",
        "        self.filename = filename\n",
        "\n",
        "    def __iter__(self):\n",
        "        with open(self.filename, 'rt', encoding='utf-8') as lines:\n",
        "            tmp = [Dataset.ROOT]\n",
        "            for line in lines:\n",
        "                line = line.rstrip()\n",
        "                if line:\n",
        "                    columns = line.split('\\t')\n",
        "                    tmp.append((columns[1], columns[3], int(columns[6])))\n",
        "                else:\n",
        "                    yield tmp\n",
        "                    tmp = [Dataset.ROOT]"
      ],
      "metadata": {
        "id": "IrvlsVZWNhoF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# read the data\n",
        "train_data = Dataset('en_ewt-ud-train-projectivized.conllu')\n",
        "dev_data = Dataset('en_ewt-ud-dev-projectivized.conllu')\n",
        "test_data = Dataset('en_ewt-ud-test-projectivized.conllu')"
      ],
      "metadata": {
        "id": "HBV3gwAJQYvf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Baseline system"
      ],
      "metadata": {
        "id": "7jiLWsPzfHUK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "eoStTWaONblj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "9gmOoMUsNgEN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PAD = '<pad>'\n",
        "UNK = '<unk>'\n",
        "\n",
        "def make_vocabs(gold_data):\n",
        "    word_dict, tag_dict = {PAD: 0, UNK: 1}, {PAD: 0}\n",
        "    for sentence in gold_data:\n",
        "        for word, tag, head in sentence:\n",
        "            if word not in word_dict:\n",
        "                word_dict[word] = len(word_dict)\n",
        "            if tag not in tag_dict:\n",
        "                tag_dict[tag] = len(tag_dict)\n",
        "    return word_dict, tag_dict\n",
        "\n",
        "def exclude_root(vocab):\n",
        "    new_vocab = {}\n",
        "    for key, value in vocab.items():\n",
        "        if key != \"<root>\":\n",
        "          new_vocab[key] = len(new_vocab)\n",
        "    return new_vocab"
      ],
      "metadata": {
        "id": "DOfY03gJNhrc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ArcStandardParser():\n",
        "    \n",
        "    MOVES = tuple(range(3))\n",
        "    SH, LA, RA = MOVES\n",
        "\n",
        "    @staticmethod\n",
        "    def initial_config(num_words):\n",
        "        return (0, [], [0]*num_words)\n",
        "\n",
        "    @staticmethod\n",
        "    def valid_moves(config):\n",
        "        valid_moves = []\n",
        "        if config[0] < len(config[2]):\n",
        "            valid_moves.append(ArcStandardParser.SH)\n",
        "        if len(config[1]) >= 3:\n",
        "            valid_moves.append(ArcStandardParser.LA)\n",
        "        if len(config[1]) >= 2:\n",
        "            valid_moves.append(ArcStandardParser.RA)\n",
        "        return valid_moves\n",
        "\n",
        "    @staticmethod\n",
        "    def next_config(config, move):\n",
        "        new_config = [int(config[0]), list(config[1]), list(config[2])]\n",
        "        if move == ArcStandardParser.SH:\n",
        "            new_config[1].append(new_config[0])\n",
        "            new_config[0] += 1\n",
        "        elif move == ArcStandardParser.LA:\n",
        "            dependent = new_config[1].pop(-2)\n",
        "            new_config[2][dependent] = new_config[1][-1]\n",
        "        elif move == ArcStandardParser.RA:\n",
        "            dependent = new_config[1].pop(-1)\n",
        "            new_config[2][dependent] = new_config[1][-1]\n",
        "        return tuple(new_config) \n",
        "\n",
        "    @staticmethod\n",
        "    def is_final_config(config):\n",
        "        return (config[0] == len(config[2]) and len(config[1]) == 1)"
      ],
      "metadata": {
        "id": "-HRP50m_Nhuc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def oracle_moves(gold_heads):\n",
        "    parser = ArcStandardParser()\n",
        "    config = parser.initial_config(len(gold_heads))\n",
        "    \n",
        "    while not parser.is_final_config(config):\n",
        "        valid_moves, move = parser.valid_moves(config), None\n",
        "\n",
        "        if (ArcStandardParser.LA in valid_moves and gold_heads[config[1][-2]] == config[1][-1] and\n",
        "            config[2].count(config[1][-2]) == gold_heads.count(config[1][-2])):\n",
        "            move = ArcStandardParser.LA\n",
        "\n",
        "        elif (ArcStandardParser.RA in valid_moves and gold_heads[config[1][-1]] == config[1][-2] and \n",
        "              config[2].count(config[1][-1]) == gold_heads.count(config[1][-1])):\n",
        "            move = ArcStandardParser.RA\n",
        "\n",
        "        elif ArcStandardParser.SH in valid_moves:\n",
        "            move = ArcStandardParser.SH\n",
        "        \n",
        "        yield (config, move)\n",
        "        config = parser.next_config(config, move)"
      ],
      "metadata": {
        "id": "PwL9hlq8Nhxd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FixedWindowModel(nn.Module):\n",
        "\n",
        "    def __init__(self, embedding_specs, hidden_dim, output_dim):\n",
        "        self.embedding_specs = embedding_specs\n",
        "        super(FixedWindowModel, self).__init__()\n",
        "        self.embeddings = nn.ModuleDict()\n",
        "        input_dim = 0\n",
        "        \n",
        "        for i, spec in enumerate(embedding_specs):\n",
        "            embedding = nn.Embedding(spec[1], spec[2])\n",
        "            nn.init.normal_(embedding.weight, mean=0.0, std=10**-2)\n",
        "            self.embeddings[\"emb\"+str(i)] = embedding\n",
        "            input_dim += spec[0]*embedding.weight.shape[1]\n",
        "\n",
        "        self.hidden = nn.Linear(input_dim, hidden_dim)\n",
        "        self.output = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, features, eval=False):\n",
        "        x = []      \n",
        "        col_indx = 0\n",
        "        for layer, spec in enumerate(self.embedding_specs):\n",
        "            for i in range(spec[0]):\n",
        "                try:\n",
        "                    current_col = features[:, col_indx:col_indx+1]\n",
        "                except:\n",
        "                    current_col = features[col_indx:col_indx+1]\n",
        "                col_indx += 1\n",
        "                embedding = self.embeddings[\"emb\"+str(layer)](current_col)\n",
        "                x.append(embedding)\n",
        "        x = torch.cat(x, dim=x[0].dim()-1).squeeze()\n",
        "        x = F.relu(self.hidden(x))\n",
        "        x = self.output(x)\n",
        "        return x if (x.dim() > 1 or eval) else x.unsqueeze(0)"
      ],
      "metadata": {
        "id": "OwmJEpCpNh0G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FixedWindowTagger():\n",
        "\n",
        "    def __init__(self, vocab_words, vocab_tags, output_dim, word_dim=50, tag_dim=10, hidden_dim=100):\n",
        "        self.embedding_specs = [(3, len(vocab_words), word_dim), (1, len(vocab_tags), tag_dim)]\n",
        "        self.model = FixedWindowModel(self.embedding_specs, hidden_dim, output_dim).to(device)\n",
        "        self.vocab_words = vocab_words\n",
        "        self.vocab_tags = vocab_tags\n",
        "\n",
        "    def featurize(self, words, i, pred_tags):\n",
        "        previous_tag = self.vocab_tags[PAD] if not pred_tags else pred_tags[-1]\n",
        "        previous_word = self.vocab_words[PAD] if i == 0 else words[i-1]\n",
        "        next_word = self.vocab_words[PAD] if i+1 >= len(words) else words[i+1]\n",
        "        return torch.LongTensor([previous_word, words[i], next_word, previous_tag])\n",
        "\n",
        "    def predict(self, words):\n",
        "        word_ids = [self.vocab_words.get(word, self.vocab_words[UNK]) for word in words]\n",
        "        predicted_tags_ids = []\n",
        "        for i, word_id in enumerate(word_ids):\n",
        "            feature = self.featurize(word_ids, i, predicted_tags_ids)\n",
        "            with torch.no_grad():\n",
        "                prediction = torch.argmax(self.model.forward(feature.to(device), eval=True))\n",
        "            predicted_tags_ids.append(prediction)\n",
        "        predicted_tags = [list(self.vocab_tags.keys())[tag_id] for tag_id in predicted_tags_ids]\n",
        "        return predicted_tags\n",
        "\n",
        "    def training_examples(self, gold_data, batch_size=100):\n",
        "        features, labels = [], []\n",
        "        for sentence in gold_data:\n",
        "            word_ids = [self.vocab_words[word] for word, tag, head in sentence]\n",
        "            tag_ids = [self.vocab_tags[tag] for word, tag, head in sentence]\n",
        "            for i in range(len(sentence)):\n",
        "                feature = self.featurize(word_ids, i, tag_ids[:i])\n",
        "                features.append(feature)\n",
        "                labels.append(tag_ids[i])\n",
        "                if len(features) == batch_size:\n",
        "                    yield torch.stack(features).to(device), torch.LongTensor(labels).to(device)\n",
        "                    features, labels = [], []\n",
        "        yield torch.stack(features).to(device), torch.LongTensor(labels).to(device)"
      ],
      "metadata": {
        "id": "x61Ua3SSNh2z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FixedWindowParser(ArcStandardParser):\n",
        "\n",
        "    def __init__(self, vocab_words, vocab_tags, word_dim=50, tag_dim=10, hidden_dim=180):\n",
        "        self.embedding_specs = [(3, len(vocab_words), word_dim), (3, len(vocab_tags), tag_dim)]\n",
        "        self.model = FixedWindowModel(self.embedding_specs, hidden_dim, len(FixedWindowParser.MOVES)).to(device)\n",
        "        self.vocab_words = vocab_words\n",
        "        self.vocab_tags = vocab_tags\n",
        "\n",
        "    def featurize(self, words, tags, config):\n",
        "        i, stack = config[0], config[1]\n",
        "        next_buffer_word = words[i] if len(words) > i else self.vocab_words[PAD]\n",
        "        top_word_stack = words[stack[-1]] if stack else self.vocab_words[PAD]\n",
        "        second_top_word_stack = words[stack[-2]] if len(stack) >= 2 else self.vocab_words[PAD]\n",
        "        next_buffer_tag = tags[i] if len(tags) > i else self.vocab_tags[PAD]\n",
        "        top_tag_stack = tags[stack[-1]] if stack else self.vocab_tags[PAD]\n",
        "        second_top_tag_stack = tags[stack[-2]] if len(stack) >= 2 else self.vocab_tags[PAD]\n",
        "        return torch.LongTensor([next_buffer_word, top_word_stack, second_top_word_stack, \n",
        "                                 next_buffer_tag, top_tag_stack, second_top_tag_stack])\n",
        "\n",
        "    def predict(self, words, tags):\n",
        "        word_ids = [self.vocab_words.get(word, self.vocab_words[UNK]) for word in words]\n",
        "        tag_ids = [self.vocab_tags[tag] for tag in tags]\n",
        "        config = self.initial_config(len(word_ids))\n",
        "        while not self.is_final_config(config):\n",
        "            feature = self.featurize(word_ids, tag_ids, config)\n",
        "            with torch.no_grad():\n",
        "                predictions = self.model.forward(feature.to(device), eval=True)\n",
        "            valid_moves = self.valid_moves(config)\n",
        "            move = valid_moves[torch.argmax(torch.tensor([pred for pred in predictions if (predictions == pred).nonzero(as_tuple=True)[0] in valid_moves])).item()]\n",
        "            config = self.next_config(config, move)\n",
        "        return config[2]\n",
        "\n",
        "    def training_examples(self, gold_data, batch_size=100):\n",
        "        features, labels = [], []\n",
        "        for sentence in gold_data:\n",
        "            word_ids = [self.vocab_words[word] for word, tag, head in sentence]\n",
        "            tag_ids = [self.vocab_tags[tag] for word, tag, head in sentence]\n",
        "            gold_heads = [head for word, tag, head in sentence]\n",
        "            for config, move in oracle_moves(gold_heads):\n",
        "                feature = self.featurize(word_ids, tag_ids, config)\n",
        "                features.append(feature)\n",
        "                labels.append(move)\n",
        "                if len(features) == batch_size:\n",
        "                    yield torch.stack(features).to(device), torch.LongTensor(labels).to(device)\n",
        "                    features, labels = [], []\n",
        "        yield torch.stack(features).to(device), torch.LongTensor(labels).to(device)"
      ],
      "metadata": {
        "id": "-1tvhce0Nh5E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TaggerParserPipeline():\n",
        "  \n",
        "  def __init__(self, vocab_words, vocab_tags):\n",
        "      # new vocabs without <root> for the tagger\n",
        "      vocab_words_no_root = exclude_root(vocab_words)\n",
        "      vocab_tags_no_root = exclude_root(vocab_tags)\n",
        "      self.tagger = FixedWindowTagger(vocab_words_no_root, vocab_tags_no_root, len(vocab_tags_no_root))\n",
        "      self.parser = FixedWindowParser(vocab_words, vocab_tags)\n",
        "\n",
        "  def predict(self, words):\n",
        "      \"\"\"Make predictions for tags and heads.\"\"\"\n",
        "      tag_preds = self.tagger.predict(words)\n",
        "      head_preds = self.parser.predict(['<root>']+words, ['<root>']+tag_preds)\n",
        "      return tag_preds, head_preds\n",
        "  \n",
        "  def train_fixed_window(self, train_data, n_epochs=2, batch_size=100, lr=1e-2, component=None): \n",
        "      \"\"\"Run training for a given component of the pipeline (either tagger or parser).\"\"\"   \n",
        "      optimizer = optim.Adam(component.model.parameters(), lr=lr)\n",
        "      info = {'epoch': 0, 'training loss': 0}\n",
        "      with tqdm(total=n_epochs) as pbar:\n",
        "          for t in range(n_epochs):\n",
        "              info['epoch'] = t + 1\n",
        "              component.model.train()\n",
        "              for bx, by in component.training_examples(train_data):\n",
        "                  optimizer.zero_grad()\n",
        "                  output = component.model.forward(bx)\n",
        "                  loss = F.cross_entropy(output, by)\n",
        "                  info['training loss'] = f'{loss:.4f}'\n",
        "                  pbar.set_postfix(info)\n",
        "                  pbar.update()\n",
        "                  loss.backward()\n",
        "                  optimizer.step()\n",
        "\n",
        "  def train(self, train_data):\n",
        "      \"\"\"Train the pipeline by first training the tagger, then \n",
        "         predicting tags on the training data which is used in training the parser.\"\"\"\n",
        "      self.train_fixed_window([sentence[1:] for sentence in train_data], component=self.tagger, n_epochs=2)\n",
        "      print(\"Predicting tags on training data...\")\n",
        "      for sentence in tqdm(train_data, total=len(list(train_data))):\n",
        "          tag_preds = self.tagger.predict([word for word, tag, head in sentence[1:]])\n",
        "          for i, word in enumerate(sentence[1:], 1):\n",
        "              sentence[i] = (word[0], tag_preds[i-1], word[2])\n",
        "      self.train_fixed_window(train_data, component=self.parser, n_epochs=1)\n",
        "\n",
        "  def evaluate(self, gold_data):\n",
        "      \"\"\"Evaluate the pipeline and print accuracy for the tagger and uas for the parser.\"\"\"\n",
        "      tagger_accuracy, uas, num_tokens = 0, 0, 0\n",
        "      for sentence in tqdm(gold_data, total=len(list(gold_data))):\n",
        "          gold_tokens, gold_tags, gold_heads = map(list, zip(*sentence[1:])) # ignores <root>\n",
        "          tag_preds, head_preds = self.predict(gold_tokens)\n",
        "          tagger_accuracy += sum([1 for pred, gold_tag in zip(tag_preds, gold_tags) if pred == gold_tag])\n",
        "          uas += sum([1 for pred, gold_head in zip(head_preds[1:], gold_heads) if pred == gold_head])\n",
        "          num_tokens += len(gold_tokens)\n",
        "      tagger_accuracy /= num_tokens\n",
        "      uas /= num_tokens\n",
        "      print(f\"\\nTagger accuracy: {tagger_accuracy:.4f} \\nParser uas: {uas:.4f}\")\n",
        "\n",
        "  def to_conllu(self, sentences):\n",
        "      \"Output a text file with parsed sentences in the conllu format.\"\n",
        "      with open(\"conllu_output.txt\", \"w\") as file:\n",
        "          file.write(f\"ID\\tFORM\\tLEMMA\\tUPOS\\tXPOS\\tFEATS\\tHEAD\\tDEPREL\\tDEPS\\tMISC\\n\\n\")\n",
        "          for sentence in sentences:\n",
        "              tag_preds, head_preds = self.predict(sentence)\n",
        "              for i in range(len(tag_preds)):\n",
        "                  file.write(f\"{i+1}\\t{sentence[i]}\\t_\\t{tag_preds[i]}\\t_\\t_\\t{head_preds[i]}\\t_\\t_\\t_\\n\")\n",
        "              file.write(\"\\n\")"
      ],
      "metadata": {
        "id": "3SAmRxzuNh7A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create the vocabularies and instantiate the pipeline\n",
        "vocab_words, vocab_tags =  make_vocabs(train_data)\n",
        "tpp = TaggerParserPipeline(vocab_words, vocab_tags)"
      ],
      "metadata": {
        "id": "TmC11eAwQadd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train the pipeline\n",
        "tpp.train(train_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tug9t9TiQdAd",
        "outputId": "7605c992-c246-4485-e73e-a9031b7d0856"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "4092it [02:04, 32.82it/s, epoch=2, training loss=0.0819]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicting tags on training data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 12543/12543 [02:19<00:00, 90.00it/s]\n",
            "4218it [02:04, 33.89it/s, epoch=1, training loss=0.0000]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate the pipeline\n",
        "tpp.evaluate(dev_data)"
      ],
      "metadata": {
        "id": "7zyIM1PjQgxo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc1cf3b1-2a69-4a44-8546-1463870941ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2001/2001 [01:09<00:00, 28.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Tagger accuracy: 0.8944 \n",
            "Parser uas: 0.6612\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# example of conllu output for the first 10 sentences in the test set (see text file)\n",
        "sentences = [[word for word, tag, head in sentence[1:]] for sentence in test_data]\n",
        "tpp.to_conllu(sentences[:10])"
      ],
      "metadata": {
        "id": "Npg2Rh_x51ei"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# BERT extention"
      ],
      "metadata": {
        "id": "1167mNAsqvzg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "!pip install -q torch-scatter -f https://data.pyg.org/whl/torch-1.10.0+cu113.html\n",
        "!pip install datasets"
      ],
      "metadata": {
        "id": "BdY0zSUHzzlJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import BertTokenizer, BertModel\n",
        "from operator import itemgetter\n",
        "from torch.utils.data import Dataset as torch_dataset\n",
        "import matplotlib.pyplot as plt\n",
        "from torch_scatter import scatter_mean\n",
        "import math\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn import init\n",
        "import datasets\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "M5mTP051q0jJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
      ],
      "metadata": {
        "id": "yPXyyJZHvXcx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Parser dataset\n",
        "Extracts words and heads from the dataset and adds the words as a single string to an input dataset xs and the list of heads to output dataset ys"
      ],
      "metadata": {
        "id": "a9yiDn0w7eTZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_label_matrix(heads):\n",
        "    label = torch.zeros(99, 100)\n",
        "    for i, head in enumerate(heads):\n",
        "        label[i, head] = 1.0\n",
        "    return label"
      ],
      "metadata": {
        "id": "DDMuB4A75n8-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ParserDataset(torch_dataset):\n",
        "    def __init__(self, dataset, max_size=None):\n",
        "        #super.__init__()\n",
        "        self.xs = []\n",
        "        self.ys = []\n",
        "        self.max_sent_len = 0\n",
        "        self.lens = []\n",
        "        \n",
        "        for sentence in dataset:\n",
        "            if self.max_sent_len < len(sentence):\n",
        "                self.max_sent_len = len(sentence)\n",
        "            self.lens.append(len(sentence))\n",
        "            if max_size != None and len(self.xs) >= max_size:\n",
        "                break\n",
        "            words, tags, heads = zip(*sentence)\n",
        "            if len(heads) < 100:\n",
        "                self.xs.append(' '.join(words[1:])) #exclude root\n",
        "                self.ys.append(get_label_matrix(heads))\n",
        "            \n",
        "    def __getitem__(self, idx):\n",
        "        return self.xs[idx], self.ys[idx]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.xs)"
      ],
      "metadata": {
        "id": "AxMuyMTxqDcd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = ParserDataset(train_data, max_size=15000) # change max later\n",
        "dev_dataset = ParserDataset(dev_data, max_size=15000)\n",
        "plt.plot(dev_dataset.lens)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "WcBs1Son-t1x",
        "outputId": "46db2ab6-c3b5-4368-d01c-db77c295a7bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Get subwords indicies\n",
        "Output from the bert model contains split words that are unknown the model, this method gets ranges of indicies where the subswords start and end"
      ],
      "metadata": {
        "id": "mfap_OId7RPL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_word_level_indicies(tok_sentence):\n",
        "    indices = []\n",
        "    subword_start, pad = 0, 0\n",
        "    for i in range(len(tok_sentence)):\n",
        "        if tok_sentence[i].startswith(\"##\") and not tok_sentence[i-1].startswith(\"##\"):\n",
        "            start = i-pad-1\n",
        "            pad += 1\n",
        "            indices.append(start)\n",
        "        elif(tok_sentence[i].startswith(\"##\") and tok_sentence[i-1].startswith(\"##\")):\n",
        "            pad += 1\n",
        "            indices.append(start)\n",
        "        else:\n",
        "            indices.append(i-pad)\n",
        "    return indices"
      ],
      "metadata": {
        "id": "swUUkVk49KV4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# example usage\n",
        "tokens = ['oscar', 'is', 'always', 'late', 'ka', '##ffe', '##ts', '.', \"hi\", \"my\", \"##name\", \"##rlfknlkrnelfkner\", \"jk\"]\n",
        "print(get_word_level_indicies(tokens))"
      ],
      "metadata": {
        "id": "QIWi8IkymC79"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Batchifyer\n",
        "Tokenizes the batches and converts them to tensors"
      ],
      "metadata": {
        "id": "vqzDHutV7D7q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BertBatcher():\n",
        "    def __init__(self, device):\n",
        "        self.device = device\n",
        "        self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "    def __call__(self, batch):\n",
        "        \n",
        "        labels = [label for sentence, label in batch]\n",
        "        sentences = [sentence for sentence, label in batch]\n",
        "\n",
        "        word_level_indicies = []\n",
        "        for sentence in sentences:\n",
        "            sent_tokens = self.tokenizer.tokenize(sentence)\n",
        "            sent_tokens = [\"[CLS]\"] + sent_tokens + [\"[SEP]\"] if len(sent_tokens) < 98 else [\"[CLS]\"] + sent_tokens[:98] + [\"[SEP]\"] # 98 = max length -2\n",
        "            sent_tokens_padded = sent_tokens + ([\"[PAD]\"] * (100 - len(sent_tokens))) if len(sent_tokens) < 100 else sent_tokens\n",
        "            word_level_indicies.append(get_word_level_indicies(sent_tokens_padded))\n",
        "\n",
        "        processed_sentence = self.tokenizer(sentences, padding=\"max_length\", return_tensors=\"pt\", max_length=100, truncation=True) #encode_plus sentence\n",
        "        input_ids, attention_mask = itemgetter(\"input_ids\", \"attention_mask\")(processed_sentence)\n",
        "\n",
        "        return (input_ids.to(self.device), \n",
        "                attention_mask.to(self.device), \n",
        "                torch.stack(labels).to(self.device), \n",
        "                torch.tensor(word_level_indicies).to((self.device)))"
      ],
      "metadata": {
        "id": "AF4JqGBbivPF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = ParserDataset(train_data, max_size=10)\n",
        "dev_dataset = ParserDataset(dev_data)\n",
        "\n",
        "# test batcher and dataloader\n",
        "bert_batcher = BertBatcher(device)\n",
        "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=32, collate_fn = bert_batcher)\n",
        "test_dataloader = torch.utils.data.DataLoader(dev_dataset, batch_size=32, collate_fn = bert_batcher)\n",
        "\n",
        "for i in train_dataloader:\n",
        "    input_ids, attention_mask, labels, word_level_indicies = i\n",
        "    break"
      ],
      "metadata": {
        "id": "hvGx2q9HiaUS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Customized BERT model\n",
        "Added linear layers on top of the bert model to specilize it"
      ],
      "metadata": {
        "id": "uFJ64JE967Ky"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomBERTModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CustomBERTModel, self).__init__()\n",
        "        self.model = BertModel.from_pretrained(\"bert-base-uncased\").to(device) ## move .to(device) outside class?\n",
        "        self.weight = nn.Parameter(torch.empty(768, 768)).to(device)\n",
        "        self.bias = nn.Parameter(torch.empty(100)).to(device)\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        bound = 1 / math.sqrt(self.weight.size(1))\n",
        "        nn.init.uniform_(self.weight, -bound, bound)\n",
        "        nn.init.uniform_(self.bias, -bound, bound)\n",
        "    \n",
        "    def forward(self, input_ids, attention_mask, word_level_indicies):\n",
        "\n",
        "        model_out  = self.model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        last_hidden_state = model_out[0]\n",
        "\n",
        "        # apply word-level pooling\n",
        "        pooled_last_hidden = scatter_mean(last_hidden_state, word_level_indicies, dim=1, dim_size=100)\n",
        "\n",
        "        X = pooled_last_hidden[:, 1:pooled_last_hidden.shape[1], :]\n",
        "        X_prime = pooled_last_hidden[ :, :pooled_last_hidden.shape[1], :]\n",
        "        \n",
        "        Y_arc = ((X @ self.weight) @ torch.transpose(X_prime, 1, -1)) + self.bias\n",
        "\n",
        "        return Y_arc"
      ],
      "metadata": {
        "id": "bbQWBvalr4ob"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test forward method\n",
        "m = CustomBERTModel()\n",
        "l = m.forward(input_ids, attention_mask, word_level_indicies).shape"
      ],
      "metadata": {
        "id": "MOnVbh5dGYIg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Training Loop\n",
        "Trains the customized bert model"
      ],
      "metadata": {
        "id": "6wQayrj06qMS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(n_epochs=3, batch_size=16, lr=1e-5):\n",
        "   \n",
        "    train_dataset = ParserDataset(train_data, max_size=15000)\n",
        "    dev_dataset = ParserDataset(dev_data, max_size=10000)\n",
        "\n",
        "    bert_batcher = BertBatcher(device)\n",
        "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size, collate_fn = bert_batcher)\n",
        "    dev_loader = torch.utils.data.DataLoader(dev_dataset, batch_size, collate_fn = bert_batcher)\n",
        "\n",
        "    custom_bert = CustomBERTModel()\n",
        "    custom_bert.train()\n",
        "    optimizer = torch.optim.AdamW(custom_bert.parameters(), lr = lr)\n",
        "\n",
        "    # Make it possible to interrupt the training\n",
        "    try:\n",
        "        for epoch in range(n_epochs):\n",
        "            with tqdm(total = len(train_loader)) as pbar:\n",
        "                custom_bert.train()\n",
        "                for input_ids, attention_mask, labels, word_level_indicies in train_loader:\n",
        "\n",
        "                    optimizer.zero_grad()\n",
        "                    output = custom_bert.forward(input_ids, attention_mask, word_level_indicies) \n",
        "                    \n",
        "                    pad_indicies = torch.argmin(attention_mask, 1, keepdim=True)\n",
        "                    weights = torch.zeros_like(output).to(device)\n",
        "                    for i, row in enumerate(weights):\n",
        "                        row[:pad_indicies[i][0], :pad_indicies[i][0]+1] = 1\n",
        "                    \n",
        "                    bce_loss = nn.BCEWithLogitsLoss(weight=weights)\n",
        "                    loss = bce_loss(output, labels)\n",
        "\n",
        "                    loss.backward(retain_graph=True)\n",
        "                    optimizer.step()\n",
        "\n",
        "                    pbar.set_postfix(loss = loss.item())\n",
        "                    pbar.update(1)\n",
        "                \n",
        "                custom_bert.eval()\n",
        "\n",
        "                accuracy, num_heads = 0, 0\n",
        "                for input_ids, attention_mask, labels, word_level_indicies in dev_loader:\n",
        "\n",
        "                    pad_indicies = torch.argmin(attention_mask, 1, keepdim=True)\n",
        "\n",
        "                    with torch.no_grad():\n",
        "                        output = custom_bert.forward(input_ids, attention_mask, word_level_indicies)\n",
        "\n",
        "                    for i, sentence in enumerate(output):\n",
        "\n",
        "                        predictions = torch.argmax(output[i], dim=1)\n",
        "                        ys = torch.argmax(labels[i], dim=1)\n",
        "\n",
        "                        predictions = predictions[1:pad_indicies[i][0].item()-1]\n",
        "                        ys = ys[1:pad_indicies[i][0].item()-1]\n",
        "\n",
        "                        accuracy += torch.sum(predictions == ys).item()\n",
        "                        num_heads += predictions.shape[0]\n",
        "\n",
        "                print(\"\\nAccuracy\",  accuracy/num_heads)\n",
        "                        \n",
        "    except KeyboardInterrupt:\n",
        "        pass\n",
        "\n",
        "    return custom_bert.model"
      ],
      "metadata": {
        "id": "Snobob-3p2Hb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = train(n_epochs=5, batch_size=32, lr=1e-5)"
      ],
      "metadata": {
        "id": "8ClXQ5QTfMRX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47c313b6-1886-4372-ebbc-6821e230d6dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "100%|██████████| 392/392 [09:21<00:00,  1.43s/it, loss=0.00937]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Accuracy 0.10842329734772757\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 392/392 [09:21<00:00,  1.43s/it, loss=0.00863]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Accuracy 0.1451752632280421\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 392/392 [09:20<00:00,  1.43s/it, loss=0.00785]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Accuracy 0.18929095028655205\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 392/392 [09:20<00:00,  1.43s/it, loss=0.00671]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Accuracy 0.2782220445155271\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 392/392 [09:21<00:00,  1.43s/it, loss=0.0057]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Accuracy 0.36768625882980144\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install gputil\n",
        "!pip install psutil\n",
        "!pip install humanize\n",
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU"
      ],
      "metadata": {
        "id": "WlS2JNO3MEyz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check gpu ram \n",
        "GPUs = GPU.getGPUs()\n",
        "# XXX: only one GPU on Colab and isn’t guaranteed\n",
        "gpu = GPUs[0]\n",
        "def printm():\n",
        "  print(gpu.name)\n",
        "  process = psutil.Process(os.getpid())\n",
        "  print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
        "  print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "printm()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jT3g-q8EMGkw",
        "outputId": "dd340afe-8adf-4e14-aee4-1779bb91251d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tesla P100-PCIE-16GB\n",
            "Gen RAM Free: 12.5 GB  | Proc size: 95.2 MB\n",
            "GPU RAM Free: 16280MB | Used: 0MB | Util   0% | Total 16280MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Evaluation\n",
        "Evaluates the trained model"
      ],
      "metadata": {
        "id": "4HnsKRUa6wWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model):\n",
        "    metric = datasets.load_metric(\"accuracy\")\n",
        "    model.eval()\n",
        "\n",
        "    for input_ids, attention_mask, labels in tqdm(test_dataloader, total=len(test_dataloader)):\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
        "\n",
        "        logits = outputs.logits\n",
        "        predictions = torch.argmax(logits, dim=-1)\n",
        "        metric.add_batch(predictions=predictions, references=labels)\n",
        "\n",
        "    return metric.compute()"
      ],
      "metadata": {
        "id": "Juu1cZDRp2Ke"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}